{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "geB3_G3UUpBT"
   },
   "source": [
    "# Domain Adversarial training of Neural Networks\n",
    "\n",
    "This notebook walks through the implementation of DANN algorithm to adapt domain from MNIST to MNIST_M.\n",
    "First, clone the git repository containing utils if not already done :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "WNrwK4-7X26X",
    "outputId": "efc004bd-e121-4eef-919a-8ba60f71238a"
   },
   "outputs": [],
   "source": [
    "# !git clone https://github.com/vcoyette/DANN\n",
    "# %cd DANN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Di9-lVRiYMVj"
   },
   "source": [
    " ## Dataset\n",
    " Download the MNIST_M dataset [here](https://drive.google.com/drive/folders/0B_tExHiYS-0vR2dNZEU4NGlSSW8), and place the archive in the data folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CSMg_Ik2ZqDC"
   },
   "outputs": [],
   "source": [
    "# !tar -xf data/mnist_m.tar.gz -C data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "D_IYmHHILXUB"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from data.utils import load_source, load_target\n",
    "from models import FeatureExtractor, Classifier, DomainRegressor\n",
    "from test import testBaseLine, testDANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "u89zLRF2e_8t"
   },
   "outputs": [],
   "source": [
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mLJRoRgcczjb"
   },
   "source": [
    "## Load Dataset\n",
    "\n",
    "Let's load the MNIST dataset as the source domain and the MNIST_M dataset as the target domain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JCO8fyp-dJdH"
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "trainloader_source, testloader_source = load_source(batch_size=batch_size,\n",
    "                                                    shuffle=True,\n",
    "                                                    num_workers=2)\n",
    "trainloader_target, testloader_target = load_target(batch_size=batch_size, \n",
    "                                                    shuffle=True, \n",
    "                                                    num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jSdEj51_dZoh"
   },
   "source": [
    "Let's plot some images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 556
    },
    "colab_type": "code",
    "id": "YvL_sEGlRRAJ",
    "outputId": "f0f9f14e-f28d-43bc-e3a1-ee804b13e617"
   },
   "outputs": [],
   "source": [
    "\n",
    "# functions to show an image\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "# get some random training images from source\n",
    "dataiter = iter(trainloader_source)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "print('Source Domain batch')\n",
    "\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "\n",
    "# get some random training images from target\n",
    "dataiter = iter(trainloader_target)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "print('Target Domain batch')\n",
    "\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bvPt4DXEg4bk"
   },
   "source": [
    "# Baseline\n",
    "\n",
    "Let's consider as a baseline a network trained on the source domain only. To remain consistent with the DANN implementation, we will use the same components (feature extractor and classifier)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lOE08FDLZAHN"
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, feature_extractor, classifier):\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        self.feature_extractor = feature_extractor\n",
    "        self.classifier = classifier\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.feature_extractor(x)\n",
    "        x = self.classifier(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "basenet = Net(FeatureExtractor(), Classifier()).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WCEQR2zuXCWG"
   },
   "outputs": [],
   "source": [
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.SGD(basenet.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 212
    },
    "colab_type": "code",
    "id": "SA4BhVBXXJ5O",
    "outputId": "00758e8e-0275-45c5-a338-b20ad1eb0779"
   },
   "outputs": [],
   "source": [
    "for epoch in range(10):\n",
    "\n",
    "    print(f'Training epoch {epoch}...')\n",
    "\n",
    "    for i, data in enumerate(trainloader_source):\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "        outputs = basenet(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "9-wCVAK9epY1",
    "outputId": "1273fe1b-b96f-41a2-c290-eb29b460cc55"
   },
   "outputs": [],
   "source": [
    "print(f'Accuracy on the source test images:'\n",
    "      f'{testBaseLine(basenet, testloader_source)} %')\n",
    "\n",
    "print(f'Accuracy on the target test images:'\n",
    "      f'{testBaseLine(basenet, testloader_target)} %')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VFQKn0ETnfPP"
   },
   "source": [
    "#DANN\n",
    "Here is the general architecture of a DANN network :\n",
    "\n",
    "![General Architecture](img/archi.png)\n",
    "\n",
    "We will define 3 torch modules:\n",
    "1. A feature Extractor (green)\n",
    "1. A classifier (blue)\n",
    "1. A Domain Regressor (pink)\n",
    "\n",
    "We will use for each module the specific architecture defined for MNIST to MNIST_M transfer in the paper:\n",
    "\n",
    "![Network Architecture](img/network.png)\n",
    "\n",
    "The modules are defined in the file models.py."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PJv-ThfTrDjE"
   },
   "source": [
    "Let's define our Gradient reversal layer : \n",
    "(discussion here: https://discuss.pytorch.org/t/solved-reverse-gradients-in-backward-pass/3589)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JxT_4qKKsJ3F"
   },
   "outputs": [],
   "source": [
    "class GradReverse(torch.autograd.Function):\n",
    "    \"\"\"Extension of grad reverse layer.\"\"\"\n",
    "    @staticmethod\n",
    "    def forward(ctx, x):\n",
    "        return x.view_as(x)\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        grad_output = grad_output.neg()\n",
    "        return grad_output, None\n",
    "\n",
    "    def grad_reverse(x):\n",
    "        return GradReverse.apply(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "V1r5D1YqabVg"
   },
   "source": [
    "We can now integrate all our modules in a single DANN network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Iw_R2SxPaYFQ"
   },
   "outputs": [],
   "source": [
    "class DANN(nn.Module):\n",
    "    def __init__(self, feature_extractor, domain_regressor, classifier):\n",
    "        super(DANN, self).__init__()\n",
    "\n",
    "        self.feature_extractor = feature_extractor\n",
    "        self.domain_regressor = domain_regressor\n",
    "        self.classifier = classifier\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.feature_extractor(x)\n",
    "        y = GradReverse.grad_reverse(x)\n",
    "        return self.classifier(x), self.domain_regressor(y)\n",
    "\n",
    "net = DANN(FeatureExtractor(), DomainRegressor(), Classifier()).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "s22Tdw4o3ESf"
   },
   "source": [
    "Let's define training parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "N9o60l1V3EG5"
   },
   "outputs": [],
   "source": [
    "# Number of epochs\n",
    "NUM_EPOCH = 100\n",
    "# Length of an epoch\n",
    "LEN_EPOCH = min(len(trainloader_source), len(trainloader_target))\n",
    "\n",
    "# Total steps in the training\n",
    "total_steps = NUM_EPOCH * LEN_EPOCH\n",
    "\n",
    "# Define criterions\n",
    "criterion_classifier = nn.NLLLoss()\n",
    "criterion_domain_regressor = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8Ayjxnm5ybnJ"
   },
   "source": [
    "We will use an SGD with a momentum of 0.9 and an adaptative learning rate as follow:\n",
    "$$\n",
    "\\mu_p = \\frac{\\mu_0}{(1+\\alpha \\cdot p)^\\beta}\n",
    "$$\n",
    "With:\n",
    "$$\n",
    "\\mu_0 = 0.01\\\\\n",
    "\\alpha = 10\\\\\n",
    "\\beta = 0.75\\\\\n",
    "p \\text{ is the training progress linearly changing from 0 to 1}\n",
    "$$\n",
    "\n",
    "As stated in the paper, the domain adaptation parameter will be set only for the feature extractor to:\n",
    "$$\n",
    "\\lambda_p = \\frac{2}{1 + e^{-\\gamma \\cdot p}} - 1\n",
    "$$\n",
    "with\n",
    "$$\n",
    "\\gamma = 10\n",
    "$$\n",
    "\n",
    "In order to set the regularization parameter only for the feature extractor, we will define a virtual learning rate of $\\mu_p / \\lambda_p$ on the domain regressor.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BBy_RwfP3fsF"
   },
   "outputs": [],
   "source": [
    "# Params\n",
    "alpha = 10\n",
    "beta = 0.75\n",
    "gamma = 10\n",
    "mu0 = 0.01\n",
    "eta = 0.9\n",
    "\n",
    "# SGD optimizer\n",
    "optimizer = optim.SGD([{'params': net.feature_extractor.parameters()},\n",
    "                       {'params': net.classifier.parameters()},\n",
    "                       {'params': net.domain_regressor.parameters()}], \n",
    "                       lr = mu0,\n",
    "                       momentum = eta)\n",
    "\n",
    "# Learning rate scheduler \n",
    "mu_p = lambda step: 1 / (1 + alpha * step / total_steps) ** beta\n",
    "\n",
    "# Virtual learning rate for the domain regressor\n",
    "def domain_regressor_lr_scheduler(step):\n",
    "    # If step=0, just returns mu_p to avoid division by zero\n",
    "    if step == 0:\n",
    "        lambda_p = 1\n",
    "    else:\n",
    "        # Compute progress\n",
    "        p = step / total_steps\n",
    "        \n",
    "        lambda_p = 2 / (1 + np.exp(-gamma * p)) - 1\n",
    "\n",
    "    return mu_p(step)/lambda_p\n",
    "  \n",
    "# Learning rate scheduler\n",
    "scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, [mu_p, mu_p, domain_regressor_lr_scheduler])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "e_Jj1e8ElpA7",
    "outputId": "6795b1f4-400c-440c-f662-4410beb59569"
   },
   "outputs": [],
   "source": [
    "# Initialize progress\n",
    "p = 0\n",
    "\n",
    "# Domain targets\n",
    "labels_domain_source = torch.zeros(batch_size).long().to(device)\n",
    "labels_domain_target = torch.ones(batch_size).long().to(device)\n",
    "\n",
    "for epoch in range(NUM_EPOCH):\n",
    "\n",
    "    print(f'Training epoch {epoch}...')\n",
    "\n",
    "    for data_source, data_target in zip(trainloader_source, trainloader_target):\n",
    "          \n",
    "        # Update progress   \n",
    "        p += 1 / total_steps\n",
    "\n",
    "        # Compute the regularization term\n",
    "        lambda_p = 2 / (1 + np.exp(-gamma * p)) - 1\n",
    "\n",
    "        # Ensure batch for source and target has same lenght\n",
    "        batch_size = min((data_source[0].shape[0], data_target[0].shape[0]))\n",
    "\n",
    "        data_source = data_source[0][:batch_size], data_source[1][:batch_size]\n",
    "        data_target = data_target[0][:batch_size], data_target[1][:batch_size]\n",
    "        labels_domain = torch.cat((labels_domain_source[:batch_size], \n",
    "                                   labels_domain_target[:batch_size]))\n",
    "\n",
    "\n",
    "        # Split and transfer to GPU\n",
    "        image_source, labels_source = data_source[0].to(device), data_source[1].to(device)\n",
    "        image_taget, labels_target = data_target[0].to(device), data_target[1].to(device)\n",
    "\n",
    "        # Source forward pass\n",
    "        src_class, src_domain = net(image_source)\n",
    "\n",
    "        # Classifier loss\n",
    "        class_loss = criterion_classifier(src_class, labels_source)\n",
    "\n",
    "        # Target forward pass\n",
    "        _, tgt_domain = net(image_taget)\n",
    "\n",
    "        # Domain Loss\n",
    "        preds_domain = torch.cat((src_domain, tgt_domain))\n",
    "        domain_loss = criterion_domain_regressor(preds_domain, labels_domain)\n",
    "\n",
    "        # Total loss\n",
    "        loss = class_loss + lambda_p * domain_loss\n",
    "\n",
    "        # Backward and Optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Scheduler step\n",
    "        scheduler.step()\n",
    "\n",
    "    print('Testing...')\n",
    "    print(f'Accuracy on source test dataset: {testDANN(net, trainloader_source)} %')\n",
    "    print(f'Accuracy on taget test dataset: {testDANN(net, trainloader_target)} %')\n",
    "\n",
    "print('Finished Training')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "DANN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
